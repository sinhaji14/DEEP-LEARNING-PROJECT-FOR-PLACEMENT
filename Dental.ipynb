{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "14L-XAHt0JtDx9tCkFlx5kj33qud_Y23J",
      "authorship_tag": "ABX9TyM1JSxxySVdGk6PrN997AcY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinhaji14/DEEP-LEARNING-PROJECT-FOR-PLACEMENT/blob/main/Dental.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWoyPVm_zHrc",
        "outputId": "268fc62f-ae02-4bea-dcec-281cb866e79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m140.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m309.8/309.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m413.6/413.6 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mcp 1.13.1 requires sse-starlette>=1.6.1, but you have sse-starlette 0.10.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Folders created: /content/dentalai\n"
          ]
        }
      ],
      "source": [
        "# ========================\n",
        "# STEP 1: Setup & Load Data\n",
        "# ========================\n",
        "\n",
        "# Install dependencies\n",
        "!pip install ultralytics fiftyone -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Mount Google Drive (if dataset is in Drive, optional)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set paths\n",
        "DATASET_DIR = \"/content/dentalai\"\n",
        "IMAGES_DIR = os.path.join(DATASET_DIR, \"images\")\n",
        "LABELS_DIR = os.path.join(DATASET_DIR, \"labels\")\n",
        "\n",
        "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
        "os.makedirs(LABELS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Folders created:\", DATASET_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 3: Convert JSON -> YOLO Segmentation\n",
        "# ==============================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "DRIVE_DATASET_PATH = \"/content/drive/MyDrive/DENTALDATASET\"   # change if needed\n",
        "OUTPUT_DATASET_PATH = \"/content/dentalai-yolo\"\n",
        "\n",
        "os.makedirs(OUTPUT_DATASET_PATH, exist_ok=True)\n",
        "\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "# Classes - only keep \"tooth\"\n",
        "CLASSES = [\"tooth\"]\n",
        "\n",
        "def convert_ann(json_file, out_label_file, class_map):\n",
        "    with open(json_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    h, w = data[\"imageHeight\"], data[\"imageWidth\"]\n",
        "    yolo_lines = []\n",
        "\n",
        "    for shape in data[\"shapes\"]:\n",
        "        label = shape[\"label\"]\n",
        "        if label not in class_map:\n",
        "            continue  # skip caries, cavity, crack\n",
        "\n",
        "        cls_id = class_map[label]\n",
        "\n",
        "        if shape[\"shape_type\"] == \"polygon\":\n",
        "            points = shape[\"points\"]\n",
        "            norm_points = []\n",
        "            for x, y in points:\n",
        "                norm_points.append(x / w)\n",
        "                norm_points.append(y / h)\n",
        "\n",
        "            line = f\"{cls_id} \" + \" \".join([f\"{p:.6f}\" for p in norm_points])\n",
        "            yolo_lines.append(line)\n",
        "\n",
        "    if yolo_lines:\n",
        "        with open(out_label_file, \"w\") as f:\n",
        "            f.write(\"\\n\".join(yolo_lines))\n",
        "\n",
        "# Process each split\n",
        "for split in splits:\n",
        "    img_dir = os.path.join(DRIVE_DATASET_PATH, split, \"img\")\n",
        "    ann_dir = os.path.join(DRIVE_DATASET_PATH, split, \"ann\")\n",
        "\n",
        "    out_img_dir = os.path.join(OUTPUT_DATASET_PATH, split, \"images\")\n",
        "    out_label_dir = os.path.join(OUTPUT_DATASET_PATH, split, \"labels\")\n",
        "\n",
        "    os.makedirs(out_img_dir, exist_ok=True)\n",
        "    os.makedirs(out_label_dir, exist_ok=True)\n",
        "\n",
        "    for file in tqdm(os.listdir(img_dir), desc=f\"Processing {split}\"):\n",
        "        if not file.endswith(\".jpg\") and not file.endswith(\".png\"):\n",
        "            continue\n",
        "\n",
        "        base = os.path.splitext(file)[0]\n",
        "        json_file = os.path.join(ann_dir, base + \".json\")\n",
        "        if not os.path.exists(json_file):\n",
        "            continue\n",
        "\n",
        "        # Copy image\n",
        "        shutil.copy(os.path.join(img_dir, file), os.path.join(out_img_dir, file))\n",
        "\n",
        "        # Convert annotation\n",
        "        out_label_file = os.path.join(out_label_dir, base + \".txt\")\n",
        "        convert_ann(json_file, out_label_file, {c: i for i, c in enumerate(CLASSES)})\n",
        "\n",
        "print(\"‚úÖ Conversion complete! YOLO dataset ready at:\", OUTPUT_DATASET_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYB7_IpF0Mus",
        "outputId": "fdb7ddd2-fbf0-4795-f856-655ef95197bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1991/1991 [00:01<00:00, 1180.88it/s]\n",
            "Processing valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 254/254 [00:00<00:00, 756.06it/s]\n",
            "Processing test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:00<00:00, 846.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Conversion complete! YOLO dataset ready at: /content/dentalai-yolo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 4: Create YOLO Dataset Config\n",
        "# ==============================\n",
        "\n",
        "yaml_content = \"\"\"\\\n",
        "path: /content/dentalai-yolo\n",
        "\n",
        "train: train/images\n",
        "val: valid/images\n",
        "test: test/images\n",
        "\n",
        "names:\n",
        "  0: tooth\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/dental.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"‚úÖ dental.yaml created at /content/dental.yaml\")\n",
        "!cat /content/dental.yaml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuEf0q6z0Mrg",
        "outputId": "0a54c699-ce8d-4640-e41b-1d0cd2eaa6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ dental.yaml created at /content/dental.yaml\n",
            "path: /content/dentalai-yolo\n",
            "\n",
            "train: train/images\n",
            "val: valid/images\n",
            "test: test/images\n",
            "\n",
            "names:\n",
            "  0: tooth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "SOURCE_DATASET = \"/content/drive/MyDrive/DENTALDATASET\"\n",
        "TARGET_DATASET = \"/content/dentalai-yolo\"\n",
        "\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    src_img_dir = os.path.join(SOURCE_DATASET, split, \"img\")\n",
        "    dst_img_dir = os.path.join(TARGET_DATASET, split, \"images\")\n",
        "    os.makedirs(dst_img_dir, exist_ok=True)\n",
        "\n",
        "    # Copy all images\n",
        "    for f in os.listdir(src_img_dir):\n",
        "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            shutil.copy(os.path.join(src_img_dir, f), os.path.join(dst_img_dir, f))\n",
        "\n",
        "print(\"‚úÖ Images copied into YOLO structure!\")\n",
        "\n",
        "# Check one split\n",
        "!ls /content/dentalai-yolo/train/images | head -10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gqPKPaP0MhY",
        "outputId": "29b8a147-cc74-4c00-f0c3-c69c632bf966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Images copied into YOLO structure!\n",
            "1000_jpg.rf.ad94534c8a4bf33d828b910160011dd9.jpg\n",
            "1001_jpg.rf.c00322f19b0c2d53472ad0181ae21683.jpg\n",
            "1002_jpg.rf.6d38658d13e1448f7275acf979722c65.jpg\n",
            "1007_jpg.rf.d08c6d48aad78ebc1ae9f48075dc628a.jpg\n",
            "1008_jpg.rf.e756a25bd9b1eca086c9e49c5fbdf9f1.jpg\n",
            "100_jpg.rf.b82625b276769d80f0c12c1f0b318d6f.jpg\n",
            "1014_jpg.rf.cfe617d31002718b8273c7094fc0f248.jpg\n",
            "1015_jpg.rf.f4a1d4ebf826db767c0bbb8b87446be8.jpg\n",
            "1018_jpg.rf.aabbf1107ffd09f3e6e0d1e7804d8eb9.jpg\n",
            "1020_jpg.rf.45bf4df271eb2b540fe792f3f8296a4f.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load pretrained YOLOv8 segmentation model\n",
        "model = YOLO(\"yolov8s-seg.pt\")\n",
        "\n",
        "# Train\n",
        "model.train(\n",
        "    data=\"/content/dental.yaml\",\n",
        "    epochs=50,           # increase if needed\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    name=\"dental_yolov8_seg\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "G5FSGKdB0MeK",
        "outputId": "2b805a1b-2367-45a4-96df-b7d9b54d3026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.194 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dental.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=dental_yolov8_seg2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/segment/dental_yolov8_seg2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset '/content/dental.yaml' error ‚ùå '/content/dental.yaml' does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    622\u001b[0m             }:\n\u001b[0;32m--> 623\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"yaml_file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \"\"\"\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/checks.py\u001b[0m in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{file}' does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: '/content/dental.yaml' does not exist",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1459866513.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model.train(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/dental.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# increase if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/segment/train.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"segment\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# avoid auto-downloading dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error ‚ùå {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overriding class names with single class.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset '/content/dental.yaml' error ‚ùå '/content/dental.yaml' does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-install ultralytics and other deps (if session restarted)\n",
        "!pip install ultralytics opencv-python-headless matplotlib -q\n",
        "\n",
        "import os, random, cv2, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Paths\n",
        "WEIGHTS = \"/content/runs/segment/dental_yolov8_seg/weights/best.pt\"  # trained weights\n",
        "IMG_DIR = \"/content/dentalai-yolo/valid/images\"                      # validation images\n",
        "OUT_DIR = \"/content/infer_vis\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Load model\n",
        "model = YOLO(WEIGHTS)\n",
        "\n",
        "# Pick a few random images\n",
        "all_imgs = [os.path.join(IMG_DIR, f) for f in os.listdir(IMG_DIR) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "sample_imgs = random.sample(all_imgs, k=min(6, len(all_imgs)))\n",
        "\n",
        "# Run inference\n",
        "results = model.predict(source=sample_imgs, imgsz=640, conf=0.25, iou=0.5, verbose=False)\n",
        "\n",
        "def overlay_mask(img_bgr, masks, alpha=0.45):\n",
        "    if masks is None or len(masks) == 0:\n",
        "        return img_bgr\n",
        "    colored = img_bgr.copy()\n",
        "    overlay = img_bgr.copy()\n",
        "    for m in masks:  # m: [H,W] boolean mask\n",
        "        color = (0, 255, 255)  # cyan\n",
        "        cnts, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cv2.drawContours(overlay, cnts, -1, color, thickness=cv2.FILLED)\n",
        "        cv2.drawContours(overlay, cnts, -1, (0, 0, 0), thickness=1)\n",
        "    return cv2.addWeighted(overlay, alpha, colored, 1 - alpha, 0)\n",
        "\n",
        "# Plot results\n",
        "n = len(results)\n",
        "cols = 3\n",
        "rows = int(np.ceil(n/cols))\n",
        "plt.figure(figsize=(16, 5*rows))\n",
        "\n",
        "for i, (img_path, res) in enumerate(zip(sample_imgs, results), 1):\n",
        "    img = cv2.imread(img_path)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # Collect masks for \"tooth\" (class 0)\n",
        "    masks = []\n",
        "    if hasattr(res, \"masks\") and res.masks is not None:\n",
        "        for cls_id, m in zip(res.boxes.cls.int().tolist(), res.masks.data):\n",
        "            if cls_id == 0:\n",
        "                mnp = m.cpu().numpy().astype(bool)\n",
        "                if mnp.shape[:2] != (h, w):\n",
        "                    mnp = cv2.resize(mnp.astype(np.uint8), (w, h), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
        "                masks.append(mnp)\n",
        "\n",
        "    vis = overlay_mask(img, masks)\n",
        "    out_path = os.path.join(OUT_DIR, os.path.basename(img_path))\n",
        "    cv2.imwrite(out_path, vis)\n",
        "\n",
        "    vis_rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(rows, cols, i)\n",
        "    plt.imshow(vis_rgb)\n",
        "    plt.title(os.path.basename(img_path))\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úÖ Inference done! Visualizations saved in: {OUT_DIR}\")\n"
      ],
      "metadata": {
        "id": "9uc6FB1Q0MW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 9 (Fix-All): Auto-locate dataset in Drive, rebuild YOLO dataset, recreate dental.yaml, quick sanity-train\n",
        "# ==============================\n",
        "!pip install -q ultralytics opencv-python-headless\n",
        "\n",
        "import os, glob, shutil, json\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --- 1) Auto-locate dataset root in Drive ---\n",
        "DRIVE_ROOTS = [\n",
        "    \"/content/drive/MyDrive\",\n",
        "    \"/content/drive/MyDrive/DENTALDATASET\",\n",
        "    \"/content/drive/MyDrive/DentalAI\",\n",
        "    \"/content/drive/MyDrive/dental\",\n",
        "]\n",
        "\n",
        "def find_dataset_root(candidates):\n",
        "    # Look for a folder that has train/img and train/ann inside it\n",
        "    for root in candidates:\n",
        "        if not os.path.isdir(root):\n",
        "            continue\n",
        "        # Search up to 3 levels deep\n",
        "        for p in glob.glob(os.path.join(root, \"**\"), recursive=True):\n",
        "            if not os.path.isdir(p):\n",
        "                continue\n",
        "            if all(os.path.isdir(os.path.join(p, s)) for s in [\"train\",\"valid\",\"test\"]):\n",
        "                # must contain img & ann inside train\n",
        "                if os.path.isdir(os.path.join(p, \"train\", \"img\")) and os.path.isdir(os.path.join(p, \"train\", \"ann\")):\n",
        "                    return p\n",
        "    return None\n",
        "\n",
        "SOURCE_DATASET = find_dataset_root(DRIVE_ROOTS)\n",
        "if SOURCE_DATASET is None:\n",
        "    # Fallback: print likely candidates to help you see options\n",
        "    print(\"‚ùå Could not auto-locate dataset. Here are some candidates:\")\n",
        "    print(\"\\n\".join(sorted(glob.glob(\"/content/drive/MyDrive/**/train\", recursive=True))[:20]))\n",
        "    raise SystemExit(\"Please set SOURCE_DATASET manually (the folder that contains train/img and train/ann).\")\n",
        "\n",
        "print(\"‚úÖ Found dataset root:\", SOURCE_DATASET)\n",
        "\n",
        "# --- 2) Create YOLO layout and copy images ---\n",
        "YOLO_DATASET = \"/content/dentalai-yolo\"\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "for s in splits:\n",
        "    src_img_dir = os.path.join(SOURCE_DATASET, s, \"img\")\n",
        "    dst_img_dir = os.path.join(YOLO_DATASET, s, \"images\")\n",
        "    dst_lab_dir = os.path.join(YOLO_DATASET, s, \"labels\")\n",
        "    os.makedirs(dst_img_dir, exist_ok=True)\n",
        "    os.makedirs(dst_lab_dir, exist_ok=True)\n",
        "\n",
        "    # Copy images if empty\n",
        "    if len([f for f in os.listdir(dst_img_dir) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]) == 0:\n",
        "        if os.path.isdir(src_img_dir):\n",
        "            for f in tqdm(sorted(os.listdir(src_img_dir)), desc=f\"Copy {s} images\"):\n",
        "                if f.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "                    shutil.copy(os.path.join(src_img_dir, f), os.path.join(dst_img_dir, f))\n",
        "\n",
        "def yolo_counts(root):\n",
        "    stats = {}\n",
        "    for s in splits:\n",
        "        ni = len([f for f in glob.glob(os.path.join(root, s, \"images\", \"*\")) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))])\n",
        "        nl = len(glob.glob(os.path.join(root, s, \"labels\", \"*.txt\")))\n",
        "        stats[s] = (ni, nl)\n",
        "    return stats\n",
        "\n",
        "print(\"Counts after copying images:\", yolo_counts(YOLO_DATASET))\n",
        "\n",
        "# --- 3) Convert LabelMe JSON -> YOLOv8 segmentation labels (tooth only) ---\n",
        "def convert_labelme_polygon(json_file, out_txt):\n",
        "    with open(json_file, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    h, w = data.get(\"imageHeight\"), data.get(\"imageWidth\")\n",
        "    if not h or not w:\n",
        "        return 0\n",
        "    lines = []\n",
        "    for sh in data.get(\"shapes\", []):\n",
        "        lbl = (sh.get(\"label\") or \"\").lower().strip()\n",
        "        if \"tooth\" not in lbl:  # keep only tooth/teeth\n",
        "            continue\n",
        "        if sh.get(\"shape_type\") != \"polygon\":\n",
        "            continue\n",
        "        pts = sh.get(\"points\", [])\n",
        "        if len(pts) < 3:\n",
        "            continue\n",
        "        norm = []\n",
        "        for x, y in pts:\n",
        "            norm.append(max(0.0, min(1.0, float(x)/w)))\n",
        "            norm.append(max(0.0, min(1.0, float(y)/h)))\n",
        "        if len(norm) >= 6:\n",
        "            lines.append(\"0 \" + \" \".join(f\"{v:.6f}\" for v in norm))\n",
        "    if lines:\n",
        "        with open(out_txt, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "        return len(lines)\n",
        "    return 0\n",
        "\n",
        "for s in splits:\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, s, \"ann\")\n",
        "    img_dir = os.path.join(YOLO_DATASET, s, \"images\")\n",
        "    lab_dir = os.path.join(YOLO_DATASET, s, \"labels\")\n",
        "    os.makedirs(lab_dir, exist_ok=True)\n",
        "\n",
        "    if not os.path.isdir(ann_dir):\n",
        "        continue\n",
        "\n",
        "    for img_path in tqdm(sorted(glob.glob(os.path.join(img_dir, \"*\"))), desc=f\"Build {s} labels\"):\n",
        "        if not img_path.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "            continue\n",
        "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        jf = os.path.join(ann_dir, base + \".json\")\n",
        "        of = os.path.join(lab_dir, base + \".txt\")\n",
        "        if os.path.exists(jf):\n",
        "            convert_labelme_polygon(jf, of)\n",
        "        # if json missing -> no label (image treated as background)\n",
        "\n",
        "print(\"Counts after building labels:\", yolo_counts(YOLO_DATASET))\n",
        "\n",
        "# --- 4) Recreate dental.yaml ---\n",
        "yaml_content = \"\"\"\\\n",
        "path: /content/dentalai-yolo\n",
        "train: train/images\n",
        "val: valid/images\n",
        "test: test/images\n",
        "names:\n",
        "  0: tooth\n",
        "\"\"\"\n",
        "with open(\"/content/dental.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "print(\"‚úÖ Wrote /content/dental.yaml\")\n",
        "\n",
        "# --- 5) Quick sanity training (3 epochs) to ensure everything works and produce best.pt ---\n",
        "# If there are zero images or zero labels, this will fail; the counts printed above will help diagnose.\n",
        "counts = yolo_counts(YOLO_DATASET)\n",
        "if any(v[0] == 0 for v in counts.values()):\n",
        "    raise SystemExit(f\"‚ùå No images detected in {YOLO_DATASET}. Please verify SOURCE_DATASET: {SOURCE_DATASET}\")\n",
        "\n",
        "print(\"üöÄ Starting quick sanity training (3 epochs)...\")\n",
        "model = YOLO(\"yolov8s-seg.pt\")\n",
        "model.train(\n",
        "    data=\"/content/dental.yaml\",\n",
        "    epochs=3,\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    name=\"dental_quickcheck_seg\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Done. Check weights at: /content/runs/segment/dental_quickcheck_seg/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "LW9qCcxdEvVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 10: Diagnose annotations & robustly rebuild YOLO labels\n",
        "# ==============================\n",
        "import os, glob, json, re, shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_DATASET = \"/content/drive/MyDrive/DENTALDATASET\"   # <- your dataset root (has train/valid/test)\n",
        "YOLO_DATASET   = \"/content/dentalai-yolo\"\n",
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "def preview_some_json(split, n=5):\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, split, \"ann\")\n",
        "    jfs = sorted(glob.glob(os.path.join(ann_dir, \"*.json\")))[:n]\n",
        "    print(f\"\\n--- Preview {split} annotations ({len(jfs)} total, showing {len(jfs[:n])}) ---\")\n",
        "    for jf in jfs:\n",
        "        with open(jf, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "        print(\"File:\", os.path.basename(jf))\n",
        "        # Print top-level keys and quick shape summary\n",
        "        print(\" keys:\", list(data.keys()))\n",
        "        shapes = data.get(\"shapes\") or data.get(\"objects\") or []\n",
        "        if isinstance(shapes, list):\n",
        "            labs = [(s.get(\"label\") or s.get(\"class\") or \"\").strip() for s in shapes if isinstance(s, dict)]\n",
        "            tys  = [(s.get(\"shape_type\") or s.get(\"type\") or \"\").strip() for s in shapes if isinstance(s, dict)]\n",
        "            print(\" labels (first 5):\", labs[:5])\n",
        "            print(\" shape_types (first 5):\", tys[:5])\n",
        "        else:\n",
        "            print(\" shapes not a list; raw:\", type(shapes))\n",
        "        # try to show image dims\n",
        "        print(\" imageHeight:\", data.get(\"imageHeight\"), \" imageWidth:\", data.get(\"imageWidth\"))\n",
        "        print(\"-\")\n",
        "\n",
        "def collect_label_stats(split):\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, split, \"ann\")\n",
        "    labels = {}\n",
        "    shape_types = {}\n",
        "    total_shapes = 0\n",
        "    tooth_like = 0\n",
        "    jfs = glob.glob(os.path.join(ann_dir, \"*.json\"))\n",
        "    for jf in jfs:\n",
        "        try:\n",
        "            with open(jf, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "        except Exception:\n",
        "            continue\n",
        "        shapes = data.get(\"shapes\") or data.get(\"objects\") or []\n",
        "        if not isinstance(shapes, list):\n",
        "            continue\n",
        "        for s in shapes:\n",
        "            if not isinstance(s, dict):\n",
        "                continue\n",
        "            lbl = (s.get(\"label\") or s.get(\"class\") or \"\").strip()\n",
        "            st  = (s.get(\"shape_type\") or s.get(\"type\") or \"\").strip()\n",
        "            labels[lbl] = labels.get(lbl, 0) + 1\n",
        "            shape_types[st] = shape_types.get(st, 0) + 1\n",
        "            total_shapes += 1\n",
        "            if re.search(r\"\\btooth|\\bteeth\", lbl, re.IGNORECASE):\n",
        "                tooth_like += 1\n",
        "    return labels, shape_types, total_shapes, tooth_like\n",
        "\n",
        "# 1) Show quick previews\n",
        "preview_some_json(\"train\", n=3)\n",
        "preview_some_json(\"valid\", n=3)\n",
        "\n",
        "# 2) Aggregate label/shape stats\n",
        "for sp in splits:\n",
        "    labs, tys, total, tooth_like = collect_label_stats(sp)\n",
        "    print(f\"\\n=== {sp.upper()} STATS ===\")\n",
        "    print(\"Total shapes:\", total, \" | tooth/teeth-like shapes:\", tooth_like)\n",
        "    print(\"Top 10 labels:\", sorted(labs.items(), key=lambda x: x[1], reverse=True)[:10])\n",
        "    print(\"Shape types:\", tys)\n",
        "\n",
        "# 3) Rebuild labels with robust rules:\n",
        "#    - Accept labels that contain 'tooth' or 'teeth' (case-insensitive), or EXACTLY one of known tooth labels if dataset uses specific naming.\n",
        "#    - Handle polygon or rectangle shapes. (circle/line/point skipped)\n",
        "import math\n",
        "\n",
        "def rect_to_polygon(points):\n",
        "    # LabelMe rectangle is usually 2 points: [x1,y1],[x2,y2]\n",
        "    if not isinstance(points, list) or len(points) != 2:\n",
        "        return None\n",
        "    (x1, y1), (x2, y2) = points\n",
        "    return [[x1,y1],[x2,y1],[x2,y2],[x1,y2]]\n",
        "\n",
        "def convert_json_to_yolo_seg(jf, out_txt):\n",
        "    with open(jf, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    h, w = data.get(\"imageHeight\"), data.get(\"imageWidth\")\n",
        "    if not h or not w:\n",
        "        return 0\n",
        "    shapes = data.get(\"shapes\") or data.get(\"objects\") or []\n",
        "    if not isinstance(shapes, list):\n",
        "        return 0\n",
        "\n",
        "    lines = []\n",
        "    for s in shapes:\n",
        "        if not isinstance(s, dict):\n",
        "            continue\n",
        "        lbl = (s.get(\"label\") or s.get(\"class\") or \"\").strip()\n",
        "        st  = (s.get(\"shape_type\") or s.get(\"type\") or \"\").strip().lower()\n",
        "        # keep only tooth-like labels\n",
        "        if not re.search(r\"\\btooth|\\bteeth\", lbl, re.IGNORECASE):\n",
        "            continue\n",
        "\n",
        "        pts = s.get(\"points\")\n",
        "        poly = None\n",
        "        if st == \"polygon\" and isinstance(pts, list) and len(pts) >= 3:\n",
        "            poly = pts\n",
        "        elif st == \"rectangle\":\n",
        "            poly = rect_to_polygon(pts)\n",
        "        else:\n",
        "            # skip unsupported shapes (circle/line/point)\n",
        "            continue\n",
        "\n",
        "        if not poly or len(poly) < 3:\n",
        "            continue\n",
        "\n",
        "        # Normalize polygon to YOLOv8-seg format: class x1 y1 x2 y2 ... (normalized 0..1)\n",
        "        norm = []\n",
        "        for x, y in poly:\n",
        "            nx = max(0.0, min(1.0, float(x) / w))\n",
        "            ny = max(0.0, min(1.0, float(y) / h))\n",
        "            norm.extend([nx, ny])\n",
        "        if len(norm) >= 6:\n",
        "            lines.append(\"0 \" + \" \".join(f\"{v:.6f}\" for v in norm))\n",
        "\n",
        "    if lines:\n",
        "        with open(out_txt, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "        return len(lines)\n",
        "    else:\n",
        "        # if no tooth polygons found, remove stale label file if exists\n",
        "        if os.path.exists(out_txt):\n",
        "            os.remove(out_txt)\n",
        "        return 0\n",
        "\n",
        "# 4) Build labels into YOLO folder\n",
        "for sp in splits:\n",
        "    img_dir = os.path.join(YOLO_DATASET, sp, \"images\")\n",
        "    lab_dir = os.path.join(YOLO_DATASET, sp, \"labels\")\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, sp, \"ann\")\n",
        "    os.makedirs(lab_dir, exist_ok=True)\n",
        "    if not os.path.isdir(img_dir):\n",
        "        print(f\"‚ö†Ô∏è Missing images dir for split {sp}: {img_dir}\")\n",
        "        continue\n",
        "    made = 0\n",
        "    for img_path in tqdm(sorted(glob.glob(os.path.join(img_dir, \"*\"))), desc=f\"Rebuild {sp} labels\"):\n",
        "        if not img_path.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "            continue\n",
        "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        jf = os.path.join(ann_dir, base + \".json\")\n",
        "        out_txt = os.path.join(lab_dir, base + \".txt\")\n",
        "        if os.path.exists(jf):\n",
        "            made += convert_json_to_yolo_seg(jf, out_txt)\n",
        "    print(f\"{sp}: wrote {made} polygons into label files.\")\n",
        "\n",
        "# 5) Count how many labels now\n",
        "def yolo_counts(root):\n",
        "    stats = {}\n",
        "    for s in splits:\n",
        "        ni = len([f for f in glob.glob(os.path.join(root, s, \"images\", \"*\")) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))])\n",
        "        nl = len(glob.glob(os.path.join(root, s, \"labels\", \"*.txt\")))\n",
        "        stats[s] = (ni, nl)\n",
        "    return stats\n",
        "\n",
        "print(\"\\nCounts after robust rebuild:\", yolo_counts(YOLO_DATASET))\n",
        "\n"
      ],
      "metadata": {
        "id": "Qb2f2JszGUIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 11: Train YOLOv8-Segmentation (full run)\n",
        "# ==============================\n",
        "!pip install -q ultralytics\n",
        "\n",
        "import os, glob\n",
        "from ultralytics import YOLO\n",
        "\n",
        "DATA_YAML = \"/content/dental.yaml\"                # created earlier\n",
        "RUN_NAME  = \"dental_teeth_seg_v1\"                 # change if you want a new run name\n",
        "\n",
        "# Sanity checks: dataset & labels must exist\n",
        "def count_items(root=\"/content/dentalai-yolo\"):\n",
        "    stats = {}\n",
        "    for s in [\"train\", \"valid\", \"test\"]:\n",
        "        ni = len([f for f in glob.glob(f\"{root}/{s}/images/*\") if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))])\n",
        "        nl = len(glob.glob(f\"{root}/{s}/labels/*.txt\"))\n",
        "        stats[s] = (ni, nl)\n",
        "    return stats\n",
        "\n",
        "stats = count_items()\n",
        "print(\"Counts (images, labels) ->\", stats)\n",
        "assert os.path.exists(DATA_YAML), \"dental.yaml not found. Recreate it before training.\"\n",
        "assert stats[\"train\"][0] > 0, \"No training images found.\"\n",
        "assert stats[\"train\"][1] > 0, \"No training labels found. Re-run the label conversion step.\"\n",
        "\n",
        "# Train\n",
        "model = YOLO(\"yolov8s-seg.pt\")  # you can switch to yolov8m-seg.pt for better accuracy\n",
        "model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=50,          # increase for better results (e.g., 100+)\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    name=RUN_NAME,\n",
        "    workers=8,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Training finished. Weights should be at /content/runs/segment/{RUN_NAME}/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "Kx5-OmWcRGM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 11 (Fix): Universal JSON/mask ‚Üí YOLOv8-Seg converter\n",
        "#  - Scans your ann/*.json to detect schema & label names\n",
        "#  - Converts polygons/rectangles to YOLOv8 segmentation .txt\n",
        "#  - If masks/ exist, converts mask PNGs to polygons\n",
        "# ==============================\n",
        "!pip install -q opencv-python-headless shapely\n",
        "\n",
        "import os, glob, json, re, cv2, numpy as np\n",
        "from tqdm import tqdm\n",
        "from shapely.geometry import Polygon\n",
        "from shapely.ops import unary_union\n",
        "\n",
        "SOURCE_DATASET = \"/content/drive/MyDrive/DENTALDATASET\"   # <-- your dataset root\n",
        "YOLO_DATASET   = \"/content/dentalai-yolo\"\n",
        "SPLITS = [\"train\",\"valid\",\"test\"]\n",
        "\n",
        "# -------- helper: ensure dirs --------\n",
        "for s in SPLITS:\n",
        "    os.makedirs(os.path.join(YOLO_DATASET, s, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(YOLO_DATASET, s, \"labels\"), exist_ok=True)\n",
        "\n",
        "# -------- helper: copy images if empty --------\n",
        "for s in SPLITS:\n",
        "    src_img = os.path.join(SOURCE_DATASET, s, \"img\")\n",
        "    dst_img = os.path.join(YOLO_DATASET, s, \"images\")\n",
        "    if os.path.isdir(src_img) and len(glob.glob(os.path.join(dst_img, \"*\"))) == 0:\n",
        "        for f in tqdm(sorted(os.listdir(src_img)), desc=f\"Copy {s} images\"):\n",
        "            if f.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "                src = os.path.join(src_img, f)\n",
        "                dst = os.path.join(dst_img, f)\n",
        "                if not os.path.exists(dst):\n",
        "                    try:\n",
        "                        os.link(src, dst)  # fast hardlink\n",
        "                    except Exception:\n",
        "                        import shutil; shutil.copy(src, dst)\n",
        "\n",
        "# -------- detection of label terms --------\n",
        "def scan_labels():\n",
        "    label_counts = {}\n",
        "    shape_types  = {}\n",
        "    has_mask_dir = {}\n",
        "    for s in SPLITS:\n",
        "        has_mask_dir[s] = os.path.isdir(os.path.join(SOURCE_DATASET, s, \"masks\"))\n",
        "        for jf in glob.glob(os.path.join(SOURCE_DATASET, s, \"ann\", \"*.json\")):\n",
        "            try:\n",
        "                data = json.load(open(jf, \"r\"))\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            # LabelMe-style\n",
        "            shapes = data.get(\"shapes\")\n",
        "            if isinstance(shapes, list):\n",
        "                for sh in shapes:\n",
        "                    if not isinstance(sh, dict): continue\n",
        "                    lbl = (sh.get(\"label\") or \"\").strip()\n",
        "                    st  = (sh.get(\"shape_type\") or \"\").strip()\n",
        "                    label_counts[lbl] = label_counts.get(lbl, 0) + 1\n",
        "                    shape_types[st]   = shape_types.get(st, 0) + 1\n",
        "\n",
        "            # COCO-per-image style (rare, but some datasets do it)\n",
        "            anns = data.get(\"annotations\")\n",
        "            cats = data.get(\"categories\")\n",
        "            if isinstance(anns, list):\n",
        "                cat_map = {}\n",
        "                if isinstance(cats, list):\n",
        "                    for c in cats:\n",
        "                        cat_map[c.get(\"id\")] = c.get(\"name\")\n",
        "                for a in anns:\n",
        "                    cid = a.get(\"category_id\")\n",
        "                    name = cat_map.get(cid, str(cid))\n",
        "                    label_counts[name] = label_counts.get(name, 0) + 1\n",
        "                    st = \"coco_poly\" if a.get(\"segmentation\") else \"coco_box\" if a.get(\"bbox\") else \"unknown\"\n",
        "                    shape_types[st] = shape_types.get(st, 0) + 1\n",
        "\n",
        "            # Supervisely\n",
        "            objs = data.get(\"objects\")\n",
        "            if isinstance(objs, list):\n",
        "                for o in objs:\n",
        "                    name = (o.get(\"classTitle\") or o.get(\"class_name\") or \"\").strip()\n",
        "                    label_counts[name] = label_counts.get(name, 0) + 1\n",
        "                    if \"points\" in o: shape_types[\"polygon\"] = shape_types.get(\"polygon\", 0) + 1\n",
        "\n",
        "            # VIA\n",
        "            regions = data.get(\"regions\")\n",
        "            if isinstance(regions, list):\n",
        "                for r in regions:\n",
        "                    ra = r.get(\"region_attributes\") or {}\n",
        "                    lbl = ra.get(\"label\") or ra.get(\"name\") or \"via_object\"\n",
        "                    label_counts[str(lbl)] = label_counts.get(str(lbl), 0) + 1\n",
        "                    sa = r.get(\"shape_attributes\") or {}\n",
        "                    st = sa.get(\"name\")\n",
        "                    shape_types[st] = shape_types.get(st, 0) + 1\n",
        "    return label_counts, shape_types, has_mask_dir\n",
        "\n",
        "label_counts, shape_types, has_mask_dir = scan_labels()\n",
        "print(\"\\n== Label name histogram (top 20) ==\")\n",
        "for k,v in sorted(label_counts.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
        "    print(f\"{k!r}: {v}\")\n",
        "print(\"\\n== Shape types ==\")\n",
        "for k,v in shape_types.items():\n",
        "    print(f\"{k!r}: {v}\")\n",
        "print(\"\\nMasks dirs present:\", has_mask_dir)\n",
        "\n",
        "# -------- label filters you want to keep as \"tooth\" ----------\n",
        "# We accept anything that *contains* these substrings:\n",
        "KEEP_REGEX = re.compile(r\"(tooth|teeth|teeths|tooth_upper|tooth_lower|upper_teeth|lower_teeth|teeth_visible|tooth_area)\", re.IGNORECASE)\n",
        "\n",
        "# If your dataset uses specific names (e.g. \"tooth_whole\", \"teeth_seg\", \"mouth_teeth\"),\n",
        "# add them to the regex above or list them here and we'll OR them in:\n",
        "ADDITIONAL_LABELS = set([\n",
        "    # e.g., \"teeth\", \"teeth_region\"\n",
        "])\n",
        "\n",
        "# -------- polygon writers --------\n",
        "def write_yolo_poly(out_txt, polys_norm):\n",
        "    \"\"\"\n",
        "    polys_norm: list of polygons, each polygon is [x1,y1,x2,y2,...] normalized 0..1\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    for norm in polys_norm:\n",
        "        if len(norm) >= 6:\n",
        "            lines.append(\"0 \" + \" \".join(f\"{v:.6f}\" for v in norm))\n",
        "    if lines:\n",
        "        with open(out_txt, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def clamp01(x):\n",
        "    return max(0.0, min(1.0, x))\n",
        "\n",
        "# unify list of (x,y) -> flat normalized\n",
        "def norm_flat(poly_xy, w, h):\n",
        "    nf = []\n",
        "    for x,y in poly_xy:\n",
        "        nf.append(clamp01(float(x)/w))\n",
        "        nf.append(clamp01(float(y)/h))\n",
        "    return nf\n",
        "\n",
        "# merge overlapping polygons with shapely (optional, keeps fewer polys)\n",
        "def merge_polygons(list_of_polys_xy):\n",
        "    try:\n",
        "        geoms = [Polygon(p) for p in list_of_polys_xy if len(p) >= 3]\n",
        "        merged = unary_union(geoms)\n",
        "        if merged.is_empty:\n",
        "            return []\n",
        "        if merged.geom_type == \"Polygon\":\n",
        "            return [np.array(merged.exterior.coords[:-1]).tolist()]\n",
        "        else:\n",
        "            out = []\n",
        "            for g in merged.geoms:\n",
        "                out.append(np.array(g.exterior.coords[:-1]).tolist())\n",
        "            return out\n",
        "    except Exception:\n",
        "        return list_of_polys_xy\n",
        "\n",
        "# -------- converters for multiple schemas --------\n",
        "def convert_labelme(data, w, h):\n",
        "    out = []\n",
        "    for sh in data.get(\"shapes\", []):\n",
        "        lbl = (sh.get(\"label\") or \"\").strip()\n",
        "        if (KEEP_REGEX.search(lbl) is None) and (lbl not in ADDITIONAL_LABELS):\n",
        "            continue\n",
        "        st = (sh.get(\"shape_type\") or \"polygon\").lower()\n",
        "        pts = sh.get(\"points\", [])\n",
        "        if st == \"rectangle\" and len(pts) == 2:\n",
        "            (x1,y1), (x2,y2) = pts\n",
        "            pts = [[x1,y1],[x2,y1],[x2,y2],[x1,y2]]\n",
        "        if len(pts) >= 3:\n",
        "            out.append(pts)\n",
        "    return out\n",
        "\n",
        "def convert_coco_per_image(data, w, h):\n",
        "    out = []\n",
        "    cats = {c.get(\"id\"): c.get(\"name\") for c in data.get(\"categories\", []) if isinstance(c, dict)}\n",
        "    for a in data.get(\"annotations\", []):\n",
        "        name = cats.get(a.get(\"category_id\"), str(a.get(\"category_id\")))\n",
        "        if (KEEP_REGEX.search(name or \"\") is None) and (name not in ADDITIONAL_LABELS):\n",
        "            continue\n",
        "        seg = a.get(\"segmentation\")\n",
        "        if isinstance(seg, list):  # polygons\n",
        "            for poly in seg:\n",
        "                # poly is flat list [x1,y1,x2,y2,...]\n",
        "                if len(poly) >= 6:\n",
        "                    # reshape to (x,y) pairs\n",
        "                    pts = list(zip(poly[0::2], poly[1::2]))\n",
        "                    out.append(pts)\n",
        "        # if RLE, skipping for simplicity; add RLE decode if your data uses it\n",
        "    return out\n",
        "\n",
        "def convert_supervisely(data, w, h):\n",
        "    out = []\n",
        "    for o in data.get(\"objects\", []):\n",
        "        name = (o.get(\"classTitle\") or o.get(\"class_name\") or \"\").strip()\n",
        "        if (KEEP_REGEX.search(name) is None) and (name not in ADDITIONAL_LABELS):\n",
        "            continue\n",
        "        if \"points\" in o and \"exterior\" in o[\"points\"]:\n",
        "            pts = o[\"points\"][\"exterior\"]  # list of [x,y]\n",
        "            if len(pts) >= 3:\n",
        "                out.append(pts)\n",
        "    return out\n",
        "\n",
        "def convert_via(data, w, h):\n",
        "    out = []\n",
        "    for r in data.get(\"regions\", []):\n",
        "        ra = r.get(\"region_attributes\") or {}\n",
        "        lbl = str(ra.get(\"label\") or ra.get(\"name\") or \"\")\n",
        "        if (KEEP_REGEX.search(lbl) is None) and (lbl not in ADDITIONAL_LABELS):\n",
        "            continue\n",
        "        sa = r.get(\"shape_attributes\") or {}\n",
        "        if sa.get(\"name\") == \"polygon\":\n",
        "            allx = sa.get(\"all_points_x\") or []\n",
        "            ally = sa.get(\"all_points_y\") or []\n",
        "            if len(allx) >= 3 and len(allx) == len(ally):\n",
        "                pts = [[x,y] for x,y in zip(allx, ally)]\n",
        "                out.append(pts)\n",
        "    return out\n",
        "\n",
        "def polygons_from_json(jf):\n",
        "    data = json.load(open(jf, \"r\"))\n",
        "    h, w = data.get(\"imageHeight\"), data.get(\"imageWidth\")\n",
        "    # If not provided, try to read from image file\n",
        "    if not (h and w):\n",
        "        # try common keys\n",
        "        h = data.get(\"height\") or data.get(\"imgHeight\")\n",
        "        w = data.get(\"width\")  or data.get(\"imgWidth\")\n",
        "    polys = []\n",
        "\n",
        "    for conv in (convert_labelme, convert_coco_per_image, convert_supervisely, convert_via):\n",
        "        try:\n",
        "            tmp = conv(data, w, h)\n",
        "            if tmp:\n",
        "                polys.extend(tmp)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Optional: merge overlaps\n",
        "    polys = merge_polygons(polys)\n",
        "    return polys, w, h\n",
        "\n",
        "# -------- masks ‚Üí polygons (fallback) --------\n",
        "def polygons_from_mask(mask_path):\n",
        "    m = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if m is None:\n",
        "        return [], 0, 0\n",
        "    h, w = m.shape[:2]\n",
        "    thr = (m > 127).astype(np.uint8)\n",
        "    contours, _ = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    polys = []\n",
        "    for c in contours:\n",
        "        if len(c) < 3:\n",
        "            continue\n",
        "        pts = c[:,0,:].tolist()  # Nx2\n",
        "        polys.append(pts)\n",
        "    polys = merge_polygons(polys)\n",
        "    return polys, w, h\n",
        "\n",
        "# -------- drive the conversion --------\n",
        "total_written = {s:0 for s in SPLITS}\n",
        "\n",
        "for s in SPLITS:\n",
        "    img_dir = os.path.join(YOLO_DATASET, s, \"images\")\n",
        "    lab_dir = os.path.join(YOLO_DATASET, s, \"labels\")\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, s, \"ann\")\n",
        "    mask_dir= os.path.join(SOURCE_DATASET, s, \"masks\")  # optional\n",
        "\n",
        "    imgs = [f for f in sorted(os.listdir(img_dir)) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    for imgname in tqdm(imgs, desc=f\"Convert {s}\"):\n",
        "        base = os.path.splitext(imgname)[0]\n",
        "        out_txt = os.path.join(lab_dir, base + \".txt\")\n",
        "\n",
        "        polys_norm = []\n",
        "        used = False\n",
        "\n",
        "        jf = os.path.join(ann_dir, base + \".json\")\n",
        "        if os.path.exists(jf):\n",
        "            polys, w, h = polygons_from_json(jf)\n",
        "            if polys and w and h:\n",
        "                for p in polys:\n",
        "                    polys_norm.append([v for xy in p for v in (max(0.0,min(1.0, xy[0]/w)), max(0.0,min(1.0, xy[1]/h)))])\n",
        "                used = True\n",
        "\n",
        "        # Fallback: mask -> polygon\n",
        "        if not used and os.path.isdir(mask_dir):\n",
        "            # try various file extensions for masks\n",
        "            for ext in (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\"):\n",
        "                mp = os.path.join(mask_dir, base + ext)\n",
        "                if os.path.exists(mp):\n",
        "                    polys, w, h = polygons_from_mask(mp)\n",
        "                    if polys and w and h:\n",
        "                        for p in polys:\n",
        "                            polys_norm.append([v for xy in p for v in (max(0.0,min(1.0, xy[0]/w)), max(0.0,min(1.0, xy[1]/h)))])\n",
        "                        used = True\n",
        "                        break\n",
        "\n",
        "        if polys_norm:\n",
        "            if write_yolo_poly(out_txt, polys_norm):\n",
        "                total_written[s] += 1\n",
        "        else:\n",
        "            # ensure no stale file left\n",
        "            if os.path.exists(out_txt):\n",
        "                os.remove(out_txt)\n",
        "\n",
        "print(\"\\n‚úÖ Done converting.\")\n",
        "print(\"Label files written per split:\", total_written)\n",
        "\n",
        "# ---- Show counts ----\n",
        "def yolo_counts(root):\n",
        "    stats = {}\n",
        "    for s in SPLITS:\n",
        "        ni = len([f for f in glob.glob(f\"{root}/{s}/images/*\") if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))])\n",
        "        nl = len(glob.glob(f\"{root}/{s}/labels/*.txt\"))\n",
        "        stats[s] = (ni, nl)\n",
        "    return stats\n",
        "\n",
        "print(\"Counts now:\", yolo_counts(YOLO_DATASET))\n"
      ],
      "metadata": {
        "id": "Gv013PodRGJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 11b: Deep-inspect one JSON + Rebuild labels (robust)\n",
        "#  - Reads image size from the actual image (not JSON)\n",
        "#  - Accepts points as [[x,y], ...] OR [{'x':..,'y':..}, ...]\n",
        "#  - Accepts label variants (Tooth/teeth etc., case-insensitive)\n",
        "# ==============================\n",
        "import os, glob, json, re, cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_DATASET = \"/content/drive/MyDrive/DENTALDATASET\"\n",
        "YOLO_DATASET   = \"/content/dentalai-yolo\"\n",
        "SPLITS = [\"train\",\"valid\",\"test\"]\n",
        "\n",
        "KEEP_REGEX = re.compile(r\"(tooth|teeth)\", re.IGNORECASE)\n",
        "\n",
        "def to_xy_list(points):\n",
        "    \"\"\"Normalize 'points' to [[x,y], ...] even if they are [{'x':..,'y':..}, ...].\"\"\"\n",
        "    if not isinstance(points, list) or len(points) == 0:\n",
        "        return []\n",
        "    if isinstance(points[0], dict) and \"x\" in points[0] and \"y\" in points[0]:\n",
        "        return [[float(p[\"x\"]), float(p[\"y\"])] for p in points if isinstance(p, dict) and \"x\" in p and \"y\" in p]\n",
        "    # else assume list of [x,y]\n",
        "    out = []\n",
        "    for p in points:\n",
        "        if isinstance(p, (list, tuple)) and len(p) >= 2:\n",
        "            out.append([float(p[0]), float(p[1])])\n",
        "    return out\n",
        "\n",
        "def write_yolo_poly(out_txt, polys_norm):\n",
        "    lines = []\n",
        "    for poly in polys_norm:\n",
        "        if len(poly) >= 6:\n",
        "            lines.append(\"0 \" + \" \".join(f\"{v:.6f}\" for v in poly))\n",
        "    if lines:\n",
        "        with open(out_txt, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def clamp01(x):\n",
        "    return max(0.0, min(1.0, x))\n",
        "\n",
        "def normalize_poly(poly_xy, w, h):\n",
        "    flat = []\n",
        "    for x, y in poly_xy:\n",
        "        flat.append(clamp01(x / w))\n",
        "        flat.append(clamp01(y / h))\n",
        "    return flat\n",
        "\n",
        "# --- Inspect a sample JSON to see actual schema ---\n",
        "sample_jsons = glob.glob(os.path.join(SOURCE_DATASET, \"train\", \"ann\", \"*.json\"))\n",
        "if sample_jsons:\n",
        "    jf = sample_jsons[0]\n",
        "    print(\"üîé Sample JSON:\", jf)\n",
        "    with open(jf, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    print(\"Top-level keys:\", list(data.keys()))\n",
        "    if \"shapes\" in data and isinstance(data[\"shapes\"], list) and data[\"shapes\"]:\n",
        "        sh = data[\"shapes\"][0]\n",
        "        print(\"First shape keys:\", list(sh.keys()))\n",
        "        print(\"First shape label:\", sh.get(\"label\"))\n",
        "        print(\"First shape type:\", sh.get(\"shape_type\"))\n",
        "        print(\"First shape points type:\", type(sh.get(\"points\")))\n",
        "        if isinstance(sh.get(\"points\"), list) and sh[\"points\"]:\n",
        "            print(\"First point example:\", sh[\"points\"][0])\n",
        "\n",
        "# --- Rebuild labels robustly using image size from actual image ---\n",
        "total_written = {s: 0 for s in SPLITS}\n",
        "total_images  = {s: 0 for s in SPLITS}\n",
        "\n",
        "for split in SPLITS:\n",
        "    img_dir = os.path.join(YOLO_DATASET, split, \"images\")\n",
        "    lab_dir = os.path.join(YOLO_DATASET, split, \"labels\")\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, split, \"ann\")\n",
        "    os.makedirs(lab_dir, exist_ok=True)\n",
        "    imgs = [f for f in sorted(os.listdir(img_dir)) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    total_images[split] = len(imgs)\n",
        "\n",
        "    for imgname in tqdm(imgs, desc=f\"Rebuild {split} labels (robust)\"):\n",
        "        base, ext = os.path.splitext(imgname)\n",
        "        img_path  = os.path.join(img_dir, imgname)\n",
        "        json_path = os.path.join(ann_dir, base + \".json\")\n",
        "        out_txt   = os.path.join(lab_dir, base + \".txt\")\n",
        "\n",
        "        # Read actual image size\n",
        "        im = cv2.imread(img_path)\n",
        "        if im is None:\n",
        "            # try uppercase extension fallback for annotations\n",
        "            continue\n",
        "        h, w = im.shape[:2]\n",
        "\n",
        "        polys_norm = []\n",
        "        if os.path.exists(json_path):\n",
        "            with open(json_path, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "            shapes = data.get(\"shapes\", [])\n",
        "            if isinstance(shapes, list):\n",
        "                for sh in shapes:\n",
        "                    lbl = (sh.get(\"label\") or \"\").strip()\n",
        "                    if not KEEP_REGEX.search(lbl):\n",
        "                        continue\n",
        "                    st = (sh.get(\"shape_type\") or \"polygon\").lower()\n",
        "                    pts_raw = sh.get(\"points\", [])\n",
        "                    pts_xy = to_xy_list(pts_raw)\n",
        "                    if st == \"rectangle\" and len(pts_xy) == 2:\n",
        "                        (x1,y1), (x2,y2) = pts_xy\n",
        "                        pts_xy = [[x1,y1],[x2,y1],[x2,y2],[x1,y2]]\n",
        "                    if len(pts_xy) >= 3:\n",
        "                        nf = normalize_poly(pts_xy, w, h)\n",
        "                        if len(nf) >= 6:\n",
        "                            polys_norm.append(nf)\n",
        "\n",
        "        if polys_norm:\n",
        "            if write_yolo_poly(out_txt, polys_norm):\n",
        "                total_written[split] += 1\n",
        "        else:\n",
        "            # ensure no stale file\n",
        "            if os.path.exists(out_txt):\n",
        "                os.remove(out_txt)\n",
        "\n",
        "print(\"\\n‚úÖ Rebuild complete.\")\n",
        "print(\"Images per split:\", total_images)\n",
        "print(\"Label files written per split:\", total_written)\n",
        "\n",
        "# --- Show a couple of label files for sanity ---\n",
        "import itertools\n",
        "for split in SPLITS:\n",
        "    some = glob.glob(os.path.join(YOLO_DATASET, split, \"labels\", \"*.txt\"))\n",
        "    if some:\n",
        "        print(f\"\\nüìÑ Example labels from {split}: {os.path.basename(some[0])}\")\n",
        "        with open(some[0], \"r\") as f:\n",
        "            for line in itertools.islice(f, 3):\n",
        "                print(\"  \", line.strip())\n",
        "        break\n"
      ],
      "metadata": {
        "id": "XQoGULYWRGGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 11c: Convert Supervisely-style JSON (objects -> points.exterior) to YOLOv8-Seg labels\n",
        "# ==============================\n",
        "import os, glob, json, re, cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_DATASET = \"/content/drive/MyDrive/DENTALDATASET\"\n",
        "YOLO_DATASET   = \"/content/dentalai-yolo\"\n",
        "SPLITS = [\"train\",\"valid\",\"test\"]\n",
        "\n",
        "KEEP_REGEX = re.compile(r\"(tooth|teeth)\", re.IGNORECASE)\n",
        "\n",
        "def clamp01(x):\n",
        "    return max(0.0, min(1.0, x))\n",
        "\n",
        "def norm_poly(poly_xy, w, h):\n",
        "    out = []\n",
        "    for x, y in poly_xy:\n",
        "        out.append(clamp01(float(x)/w))\n",
        "        out.append(clamp01(float(y)/h))\n",
        "    return out\n",
        "\n",
        "def write_yolo_poly(out_txt, polys_norm):\n",
        "    lines = []\n",
        "    for poly in polys_norm:\n",
        "        if len(poly) >= 6:\n",
        "            lines.append(\"0 \" + \" \".join(f\"{v:.6f}\" for v in poly))\n",
        "    if lines:\n",
        "        os.makedirs(os.path.dirname(out_txt), exist_ok=True)\n",
        "        with open(out_txt, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "written = {s:0 for s in SPLITS}\n",
        "total   = {s:0 for s in SPLITS}\n",
        "\n",
        "for split in SPLITS:\n",
        "    img_dir = os.path.join(YOLO_DATASET, split, \"images\")\n",
        "    lab_dir = os.path.join(YOLO_DATASET, split, \"labels\")\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, split, \"ann\")\n",
        "    os.makedirs(lab_dir, exist_ok=True)\n",
        "\n",
        "    imgs = [f for f in sorted(os.listdir(img_dir)) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    total[split] = len(imgs)\n",
        "\n",
        "    for imgname in tqdm(imgs, desc=f\"Supervisely -> YOLO ({split})\"):\n",
        "        base, _ = os.path.splitext(imgname)\n",
        "        img_path = os.path.join(img_dir, imgname)\n",
        "        jf       = os.path.join(ann_dir, base + \".json\")\n",
        "        out_txt  = os.path.join(lab_dir, base + \".txt\")\n",
        "\n",
        "        polys_norm = []\n",
        "\n",
        "        # read image size from the image itself\n",
        "        im = cv2.imread(img_path)\n",
        "        if im is None or not os.path.exists(jf):\n",
        "            # ensure no stale label\n",
        "            if os.path.exists(out_txt):\n",
        "                os.remove(out_txt)\n",
        "            continue\n",
        "        h, w = im.shape[:2]\n",
        "\n",
        "        try:\n",
        "            data = json.load(open(jf, \"r\"))\n",
        "        except Exception:\n",
        "            if os.path.exists(out_txt):\n",
        "                os.remove(out_txt)\n",
        "            continue\n",
        "\n",
        "        # Supervisely schema: data['objects'] -> each has 'classTitle' and 'points': {'exterior': [[x,y],...], 'interior': [...]}\n",
        "        objects = data.get(\"objects\", [])\n",
        "        for obj in objects:\n",
        "            label = (obj.get(\"classTitle\") or obj.get(\"class_name\") or \"\").strip()\n",
        "            if not KEEP_REGEX.search(label):\n",
        "                continue\n",
        "\n",
        "            pts = None\n",
        "            if isinstance(obj.get(\"points\"), dict):\n",
        "                ext = obj[\"points\"].get(\"exterior\")\n",
        "                if isinstance(ext, list) and len(ext) >= 3:\n",
        "                    pts = [[float(x), float(y)] for x,y in ext]\n",
        "\n",
        "            # Fallback if exterior missing but generic 'points' is a list\n",
        "            if pts is None and isinstance(obj.get(\"points\"), list) and len(obj[\"points\"]) >= 3:\n",
        "                pts = []\n",
        "                for p in obj[\"points\"]:\n",
        "                    if isinstance(p, dict) and \"x\" in p and \"y\" in p:\n",
        "                        pts.append([float(p[\"x\"]), float(p[\"y\"])])\n",
        "                    elif isinstance(p, (list, tuple)) and len(p) >= 2:\n",
        "                        pts.append([float(p[0]), float(p[1])])\n",
        "\n",
        "            if pts and len(pts) >= 3:\n",
        "                poly = norm_poly(pts, w, h)\n",
        "                if len(poly) >= 6:\n",
        "                    polys_norm.append(poly)\n",
        "\n",
        "        if polys_norm:\n",
        "            if write_yolo_poly(out_txt, polys_norm):\n",
        "                written[split] += 1\n",
        "        else:\n",
        "            if os.path.exists(out_txt):\n",
        "                os.remove(out_txt)\n",
        "\n",
        "print(\"\\n‚úÖ Supervisely conversion complete.\")\n",
        "print(\"Images per split:\", total)\n",
        "print(\"Label files written per split:\", written)\n",
        "\n",
        "# Quick count\n",
        "def yolo_counts(root=\"/content/dentalai-yolo\"):\n",
        "    out = {}\n",
        "    for s in SPLITS:\n",
        "        ni = len([f for f in glob.glob(f\"{root}/{s}/images/*\") if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "        nl = len(glob.glob(f\"{root}/{s}/labels/*.txt\"))\n",
        "        out[s] = (ni, nl)\n",
        "    return out\n",
        "\n",
        "print(\"Counts now:\", yolo_counts())\n"
      ],
      "metadata": {
        "id": "kc2UyQGJYioc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 11d: Robust filename matching (handles *.jpg.json / *.png.json)\n",
        "# ==============================\n",
        "import os, glob, json, re, cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_DATASET = \"/content/drive/MyDrive/DENTALDATASET\"\n",
        "YOLO_DATASET   = \"/content/dentalai-yolo\"\n",
        "SPLITS = [\"train\",\"valid\",\"test\"]\n",
        "\n",
        "KEEP_REGEX = re.compile(r\"(tooth|teeth)\", re.IGNORECASE)\n",
        "\n",
        "def clamp01(x):\n",
        "    return max(0.0, min(1.0, x))\n",
        "\n",
        "def norm_poly(poly_xy, w, h):\n",
        "    out = []\n",
        "    for x, y in poly_xy:\n",
        "        out.append(clamp01(float(x)/w))\n",
        "        out.append(clamp01(float(y)/h))\n",
        "    return out\n",
        "\n",
        "def write_yolo_poly(out_txt, polys_norm):\n",
        "    lines = []\n",
        "    for poly in polys_norm:\n",
        "        if len(poly) >= 6:\n",
        "            lines.append(\"0 \" + \" \".join(f\"{v:.6f}\" for v in poly))\n",
        "    if lines:\n",
        "        os.makedirs(os.path.dirname(out_txt), exist_ok=True)\n",
        "        with open(out_txt, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def find_ann_for_image(ann_dir, base, img_ext):\n",
        "    \"\"\"\n",
        "    Try multiple patterns:\n",
        "      base + \".json\"\n",
        "      base + img_ext + \".json\" where img_ext is \".jpg\"/\".png\"/\".jpeg\" (as seen in your dataset)\n",
        "    Return the first that exists (case-insensitive).\n",
        "    \"\"\"\n",
        "    candidates = [\n",
        "        os.path.join(ann_dir, base + \".json\"),\n",
        "        os.path.join(ann_dir, base + img_ext + \".json\"),\n",
        "    ]\n",
        "    # Case-insensitive fallback scan (only if needed)\n",
        "    if not any(os.path.exists(p) for p in candidates):\n",
        "        # scan ann_dir for files that start with base and endwith .json\n",
        "        globbed = glob.glob(os.path.join(ann_dir, base + \"*\"))\n",
        "        for p in globbed:\n",
        "            if p.lower().endswith(\".json\"):\n",
        "                return p\n",
        "        return None\n",
        "    for p in candidates:\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "written = {s:0 for s in SPLITS}\n",
        "total   = {s:0 for s in SPLITS}\n",
        "\n",
        "for split in SPLITS:\n",
        "    img_dir = os.path.join(YOLO_DATASET, split, \"images\")\n",
        "    lab_dir = os.path.join(YOLO_DATASET, split, \"labels\")\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, split, \"ann\")\n",
        "    os.makedirs(lab_dir, exist_ok=True)\n",
        "\n",
        "    imgs = [f for f in sorted(os.listdir(img_dir)) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    total[split] = len(imgs)\n",
        "\n",
        "    for imgname in tqdm(imgs, desc=f\"Match+Convert ({split})\"):\n",
        "        base, img_ext = os.path.splitext(imgname)  # img_ext includes dot, like \".jpg\"\n",
        "        img_path = os.path.join(img_dir, imgname)\n",
        "        out_txt  = os.path.join(lab_dir, base + \".txt\")\n",
        "\n",
        "        # read image size\n",
        "        im = cv2.imread(img_path)\n",
        "        if im is None:\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "            continue\n",
        "        h, w = im.shape[:2]\n",
        "\n",
        "        jf = find_ann_for_image(ann_dir, base, img_ext)\n",
        "        if jf is None:\n",
        "            # no annotation for this image -> remove label if any\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "            continue\n",
        "\n",
        "        # parse Supervisely-like JSON\n",
        "        try:\n",
        "            data = json.load(open(jf, \"r\"))\n",
        "        except Exception:\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "            continue\n",
        "\n",
        "        objects = data.get(\"objects\", [])\n",
        "        polys_norm = []\n",
        "        for obj in objects:\n",
        "            label = (obj.get(\"classTitle\") or obj.get(\"class_name\") or \"\").strip()\n",
        "            if not KEEP_REGEX.search(label):\n",
        "                continue\n",
        "\n",
        "            pts = None\n",
        "            # Standard Supervisely polygon: points.exterior = [[x,y], ...]\n",
        "            if isinstance(obj.get(\"points\"), dict):\n",
        "                ext = obj[\"points\"].get(\"exterior\")\n",
        "                if isinstance(ext, list) and len(ext) >= 3:\n",
        "                    # handle either [[x,y], ...] or [{'x':..,'y':..}, ...]\n",
        "                    if isinstance(ext[0], dict) and \"x\" in ext[0] and \"y\" in ext[0]:\n",
        "                        pts = [[float(p[\"x\"]), float(p[\"y\"])] for p in ext]\n",
        "                    else:\n",
        "                        pts = [[float(p[0]), float(p[1])] for p in ext if isinstance(p, (list, tuple)) and len(p) >= 2]\n",
        "\n",
        "            # Fallback: generic list in 'points'\n",
        "            if pts is None and isinstance(obj.get(\"points\"), list) and len(obj[\"points\"]) >= 3:\n",
        "                pts = []\n",
        "                for p in obj[\"points\"]:\n",
        "                    if isinstance(p, dict) and \"x\" in p and \"y\" in p:\n",
        "                        pts.append([float(p[\"x\"]), float(p[\"y\"])])\n",
        "                    elif isinstance(p, (list, tuple)) and len(p) >= 2:\n",
        "                        pts.append([float(p[0]), float(p[1])])\n",
        "\n",
        "            if pts and len(pts) >= 3:\n",
        "                poly = norm_poly(pts, w, h)\n",
        "                if len(poly) >= 6:\n",
        "                    polys_norm.append(poly)\n",
        "\n",
        "        if polys_norm:\n",
        "            if write_yolo_poly(out_txt, polys_norm):\n",
        "                written[split] += 1\n",
        "        else:\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "\n",
        "print(\"\\n‚úÖ Rebuild with robust filename matching complete.\")\n",
        "print(\"Images per split:\", total)\n",
        "print(\"Label files written per split:\", written)\n",
        "\n",
        "# Show counts\n",
        "def yolo_counts(root=\"/content/dentalai-yolo\"):\n",
        "    out = {}\n",
        "    for s in SPLITS:\n",
        "        ni = len([f for f in glob.glob(f\"{root}/{s}/images/*\") if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "        nl = len(glob.glob(f\"{root}/{s}/labels/*.txt\"))\n",
        "        out[s] = (ni, nl)\n",
        "    return out\n",
        "\n",
        "print(\"Counts now:\", yolo_counts())\n"
      ],
      "metadata": {
        "id": "mneGI4MDZ37M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP 12: If labels still 0 ‚Üí build from masks (contours) and TRAIN YOLOv8-Seg\n",
        "# ==============================\n",
        "!pip install -q ultralytics opencv-python-headless\n",
        "\n",
        "import os, glob, cv2, numpy as np\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "SOURCE_DATASET = \"/content/drive/MyDrive/DENTALDATASET\"   # root with train/valid/test\n",
        "YOLO_DATASET   = \"/content/dentalai-yolo\"\n",
        "DATA_YAML      = \"/content/dental.yaml\"\n",
        "RUN_NAME       = \"dental_teeth_seg_v2\"\n",
        "\n",
        "SPLITS = [\"train\",\"valid\",\"test\"]\n",
        "\n",
        "def count_items(root=YOLO_DATASET):\n",
        "    stats = {}\n",
        "    for s in SPLITS:\n",
        "        ni = len([f for f in glob.glob(f\"{root}/{s}/images/*\") if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))])\n",
        "        nl = len(glob.glob(f\"{root}/{s}/labels/*.txt\"))\n",
        "        stats[s] = (ni, nl)\n",
        "    return stats\n",
        "\n",
        "def masks_to_yolo_labels(split):\n",
        "    \"\"\"Create YOLOv8-seg labels from binary masks (any nonzero as teeth).\"\"\"\n",
        "    img_dir = os.path.join(YOLO_DATASET, split, \"images\")\n",
        "    lab_dir = os.path.join(YOLO_DATASET, split, \"labels\"); os.makedirs(lab_dir, exist_ok=True)\n",
        "    mask_dir = os.path.join(SOURCE_DATASET, split, \"masks\")\n",
        "    if not os.path.isdir(mask_dir):\n",
        "        return 0\n",
        "    written = 0\n",
        "    imgs = [f for f in sorted(os.listdir(img_dir)) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "    for imgname in tqdm(imgs, desc=f\"Mask‚ÜíYOLO ({split})\"):\n",
        "        base, _ = os.path.splitext(imgname)\n",
        "        out_txt = os.path.join(lab_dir, base + \".txt\")\n",
        "\n",
        "        # try to find a matching mask by common extensions\n",
        "        mask_path = None\n",
        "        for ext in (\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\"):\n",
        "            p = os.path.join(mask_dir, base + ext)\n",
        "            if os.path.exists(p):\n",
        "                mask_path = p; break\n",
        "        if mask_path is None:\n",
        "            # sometimes masks keep original extension in name (e.g., xxx.jpg.png)\n",
        "            cands = glob.glob(os.path.join(mask_dir, base + \".*\"))\n",
        "            cands = [c for c in cands if c.lower().endswith((\".png\",\".jpg\",\".jpeg\",\".bmp\",\".tif\",\".tiff\"))]\n",
        "            if cands: mask_path = cands[0]\n",
        "        if mask_path is None:\n",
        "            # no mask for this image -> skip\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "            continue\n",
        "\n",
        "        m = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if m is None:\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "            continue\n",
        "\n",
        "        h, w = m.shape[:2]\n",
        "        # binarize\n",
        "        thr = (m > 127).astype(np.uint8)\n",
        "        # find contours\n",
        "        contours, _ = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        lines = []\n",
        "        for c in contours:\n",
        "            if len(c) < 3:\n",
        "                continue\n",
        "            # simplify tiny specks\n",
        "            if cv2.contourArea(c) < 20:\n",
        "                continue\n",
        "            pts = c[:,0,:]  # Nx2\n",
        "            # normalize to [0,1]\n",
        "            flat = []\n",
        "            for x, y in pts:\n",
        "                flat.append(max(0.0, min(1.0, float(x)/w)))\n",
        "                flat.append(max(0.0, min(1.0, float(y)/h)))\n",
        "            if len(flat) >= 6:\n",
        "                lines.append(\"0 \" + \" \".join(f\"{v:.6f}\" for v in flat))\n",
        "\n",
        "        if lines:\n",
        "            with open(out_txt, \"w\") as f:\n",
        "                f.write(\"\\n\".join(lines))\n",
        "            written += 1\n",
        "        else:\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "    return written\n",
        "\n",
        "# 1) If any split has 0 labels, try building from masks for that split\n",
        "stats_before = count_items()\n",
        "print(\"Before mask conversion:\", stats_before)\n",
        "made_total = {}\n",
        "for s in SPLITS:\n",
        "    if stats_before[s][1] == 0:\n",
        "        made_total[s] = masks_to_yolo_labels(s)\n",
        "    else:\n",
        "        made_total[s] = 0\n",
        "print(\"Labels created from masks:\", made_total)\n",
        "\n",
        "# 2) Re-count; assert train has labels\n",
        "stats_after = count_items()\n",
        "print(\"After mask conversion:\", stats_after)\n",
        "assert stats_after[\"train\"][1] > 0, \"Still no training labels. Check that your /train/masks exist and match image names.\"\n",
        "\n",
        "# 3) Train YOLOv8-Seg\n",
        "model = YOLO(\"yolov8s-seg.pt\")\n",
        "model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    name=RUN_NAME,\n",
        "    workers=8,\n",
        "    verbose=True\n",
        ")\n",
        "print(f\"\\n‚úÖ Training finished. Weights ‚Üí /content/runs/segment/{RUN_NAME}/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "Hbqit87MbA-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VzKM-k484TCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEP: Inference + Natural Teeth Whitening (auto-find weights)\n",
        "# ==============================\n",
        "!pip install -q ultralytics opencv-python-headless mediapipe matplotlib numpy\n",
        "\n",
        "import os, glob, cv2, numpy as np, matplotlib.pyplot as plt, random\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --------- helper: find latest best.pt ----------\n",
        "def find_latest_best(root=\"/content/runs/segment\"):\n",
        "    candidates = glob.glob(os.path.join(root, \"**\", \"weights\", \"best.pt\"), recursive=True)\n",
        "    if not candidates:\n",
        "        raise FileNotFoundError(\"No trained weights found under /content/runs/segment. Train the model first.\")\n",
        "    candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
        "    return candidates[0]\n",
        "\n",
        "WEIGHTS = find_latest_best()\n",
        "print(\"Using weights:\", WEIGHTS)\n",
        "\n",
        "# --------- paths ----------\n",
        "IMG_DIR = \"/content/dentalai-yolo/valid/images\"   # change if you want train or test\n",
        "OUT_DIR = \"/content/teeth_whitening_out\"\n",
        "VIS_DIR = os.path.join(OUT_DIR, \"vis\")\n",
        "WHITEN_DIR = os.path.join(OUT_DIR, \"whitened\")\n",
        "MASK_DIR = os.path.join(OUT_DIR, \"masks\")\n",
        "os.makedirs(VIS_DIR, exist_ok=True)\n",
        "os.makedirs(WHITEN_DIR, exist_ok=True)\n",
        "os.makedirs(MASK_DIR, exist_ok=True)\n",
        "\n",
        "# --------- load model ----------\n",
        "model = YOLO(WEIGHTS)\n",
        "\n",
        "# --------- Mediapipe for mouth-open check ----------\n",
        "import mediapipe as mp\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
        "\n",
        "def is_mouth_open(img_rgb, threshold=0.03):\n",
        "    \"\"\"Return True if mouth appears open. Uses distance ratio between upper/lower lip landmarks.\"\"\"\n",
        "    results = face_mesh.process(img_rgb)\n",
        "    if not results.multi_face_landmarks:\n",
        "        return False\n",
        "    lm = results.multi_face_landmarks[0].landmark\n",
        "    # Mediapipe landmarks: use inner lip top/bottom (indexes 13,14 or refined indices)\n",
        "    # Fallback robust pair:\n",
        "    # upper inner lip: 13, lower inner lip: 14 (common mapping) ‚Äî use normalized y distance relative to face height\n",
        "    try:\n",
        "        top = lm[13]\n",
        "        bottom = lm[14]\n",
        "    except Exception:\n",
        "        # refined indices can differ; try alternative indices (depends on model)\n",
        "        top = lm[0]; bottom = lm[17]\n",
        "    # vertical distance normalized by image height\n",
        "    h = img_rgb.shape[0]\n",
        "    mouth_gap = abs((bottom.y - top.y))\n",
        "    return mouth_gap > threshold\n",
        "\n",
        "# --------- Whitening function ----------\n",
        "def whiten_teeth(img_bgr, mask_bool, intensity=0.20, clahe_clip=2.0, blend_alpha=0.85):\n",
        "    \"\"\"\n",
        "    img_bgr: input image (BGR)\n",
        "    mask_bool: boolean mask where True => teeth pixels\n",
        "    intensity: proportion to move L channel toward 255 (0..1)\n",
        "    clahe_clip: CLAHE clip limit\n",
        "    blend_alpha: how much whitened region to keep (0..1)\n",
        "    \"\"\"\n",
        "    if mask_bool.sum() == 0:\n",
        "        return img_bgr\n",
        "\n",
        "    img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
        "    L, A, B = cv2.split(img_lab)\n",
        "\n",
        "    # Apply CLAHE to L channel (global but we'll later blend only in mask)\n",
        "    clahe = cv2.createCLAHE(clipLimit=clahe_clip, tileGridSize=(8,8))\n",
        "    L_clahe = clahe.apply(L.astype(np.uint8)).astype(np.float32)\n",
        "\n",
        "    # Create targeted L: move teeth pixels toward brighter values but keep natural contrast\n",
        "    target_L = L_clahe\n",
        "    # Increase brightness within mask proportionally (not full 255)\n",
        "    # For masked pixels: L_new = L + intensity*(255 - L)\n",
        "    mask_f = mask_bool.astype(np.float32)\n",
        "    L_new = L.copy()\n",
        "    L_new = L_new + mask_f * intensity * (255.0 - L_new)\n",
        "\n",
        "    # Also blend some of CLAHE effect to avoid flatness\n",
        "    L_new = (1 - 0.35*mask_f) * L_new + (0.35*mask_f) * L_clahe\n",
        "\n",
        "    # Merge back\n",
        "    lab_new = cv2.merge([np.clip(L_new,0,255).astype(np.uint8), A.astype(np.uint8), B.astype(np.uint8)])\n",
        "    whitened_bgr = cv2.cvtColor(lab_new, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Soften mask edges with gaussian blur (feather)\n",
        "    mask_uint8 = (mask_bool.astype(np.uint8) * 255)\n",
        "    k = max(7, int(round(min(img_bgr.shape[:2]) * 0.01)))  # kernel scales with image size\n",
        "    if k % 2 == 0: k += 1\n",
        "    mask_blur = cv2.GaussianBlur(mask_uint8, (k,k), 0).astype(np.float32)/255.0\n",
        "    mask_blur = cv2.merge([mask_blur, mask_blur, mask_blur])\n",
        "\n",
        "    # Blend: keep original outside mask, combine inside\n",
        "    blended = (img_bgr.astype(np.float32) * (1 - mask_blur) + (blend_alpha*whitened_bgr.astype(np.float32) + (1-blend_alpha)*img_bgr.astype(np.float32)) * mask_blur).astype(np.uint8)\n",
        "    return blended\n",
        "\n",
        "# --------- Run inference & apply whitening ----------\n",
        "all_imgs = [os.path.join(IMG_DIR, f) for f in sorted(os.listdir(IMG_DIR)) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
        "sample_imgs = all_imgs  # process all; change to random.sample(all_imgs, k=20) to test fewer\n",
        "\n",
        "print(\"Processing\", len(sample_imgs), \"images... (this may take a while)\")\n",
        "\n",
        "for img_path in sample_imgs:\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        continue\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # 1) check mouth open; if not open, skip whitening but still save mask/vis\n",
        "    mouth_open = False\n",
        "    try:\n",
        "        mouth_open = is_mouth_open(img_rgb, threshold=0.035)\n",
        "    except Exception:\n",
        "        mouth_open = True  # conservative fallback: proceed if face detection fails\n",
        "\n",
        "    # 2) run model prediction (single-image)\n",
        "    res = model.predict(source=img_path, imgsz=640, conf=0.25, iou=0.5, verbose=False)[0]\n",
        "\n",
        "    # 3) build combined mask for class 0 (tooth)\n",
        "    H, W = img.shape[:2]\n",
        "    mask_comb = np.zeros((H,W), dtype=np.uint8)\n",
        "    if hasattr(res, \"masks\") and res.masks is not None:\n",
        "        # res.masks.data : list/tensor of masks in model's output size; res.boxes.cls holds classes\n",
        "        cls_list = res.boxes.cls.int().tolist() if res.boxes is not None else []\n",
        "        masks_data = res.masks.data if res.masks is not None else []\n",
        "        for cls_id, m in zip(cls_list, masks_data):\n",
        "            if int(cls_id) != 0:  # tooth class id\n",
        "                continue\n",
        "            mnp = m.cpu().numpy().astype(np.uint8)\n",
        "            # resize mask to original size if needed\n",
        "            if mnp.shape[:2] != (H,W):\n",
        "                mnp = cv2.resize(mnp, (W,H), interpolation=cv2.INTER_NEAREST)\n",
        "            mask_comb = np.maximum(mask_comb, mnp)\n",
        "\n",
        "    mask_bool = (mask_comb > 0)\n",
        "\n",
        "    # Save mask visualization\n",
        "    mask_vis = (mask_comb*255).astype(np.uint8)\n",
        "    cv2.imwrite(os.path.join(MASK_DIR, os.path.basename(img_path)), mask_vis)\n",
        "\n",
        "    # 4) If mouth not open or mask empty: only save visualization and skip whitening\n",
        "    basefn = os.path.basename(img_path)\n",
        "    vis = img.copy()\n",
        "    if mask_bool.sum() > 0:\n",
        "        # overlay mask in cyan for visualization\n",
        "        overlay = vis.copy()\n",
        "        contours, _ = cv2.findContours(mask_comb, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cv2.drawContours(overlay, contours, -1, (0,255,255), thickness=cv2.FILLED)\n",
        "        vis = cv2.addWeighted(overlay, 0.45, vis, 0.55, 0)\n",
        "    # annotate mouth-open status\n",
        "    txt = \"MOUTH_OPEN\" if mouth_open else \"MOUTH_CLOSED\"\n",
        "    cv2.putText(vis, txt, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)\n",
        "    cv2.imwrite(os.path.join(VIS_DIR, basefn), vis)\n",
        "\n",
        "    if (not mouth_open) or (mask_bool.sum() == 0):\n",
        "        # save original to whitened folder as-is (no change)\n",
        "        cv2.imwrite(os.path.join(WHITEN_DIR, basefn), img)\n",
        "        continue\n",
        "\n",
        "    # 5) apply whitening\n",
        "    whitened = whiten_teeth(img, mask_bool, intensity=0.22, clahe_clip=2.0, blend_alpha=0.9)\n",
        "    cv2.imwrite(os.path.join(WHITEN_DIR, basefn), whitened)\n",
        "\n",
        "print(\"Done. Visualizations ->\", VIS_DIR)\n",
        "print(\"Masks ->\", MASK_DIR)\n",
        "print(\"Whitened images ->\", WHITEN_DIR)\n",
        "\n",
        "# Quick display (show 6 samples)\n",
        "to_show = sorted(glob.glob(os.path.join(WHITEN_DIR,\"*\")) )[:6]\n",
        "plt.figure(figsize=(14,8))\n",
        "for i,p in enumerate(to_show,1):\n",
        "    im = cv2.cvtColor(cv2.imread(p), cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(2,3,i); plt.imshow(im); plt.title(os.path.basename(p)); plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fj5VJrnLhgt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CHECK / TRAIN (auto) ‚Äî list runs, check labels, optionally quick-train\n",
        "# ==============================\n",
        "!pip install -q ultralytics opencv-python-headless\n",
        "\n",
        "import os, glob, json\n",
        "from ultralytics import YOLO\n",
        "\n",
        "YOLO_DATASET = \"/content/dentalai-yolo\"\n",
        "RUNS_DIR = \"/content/runs/segment\"\n",
        "\n",
        "def list_runs(root=RUNS_DIR):\n",
        "    runs = glob.glob(os.path.join(root, \"*\"))\n",
        "    runs = [r for r in runs if os.path.isdir(r)]\n",
        "    if not runs:\n",
        "        print(\"No runs found in\", root)\n",
        "    else:\n",
        "        print(\"Found runs:\")\n",
        "        for r in sorted(runs, key=os.path.getmtime, reverse=True)[:10]:\n",
        "            wp = glob.glob(os.path.join(r, \"weights\", \"*.pt\"))\n",
        "            print(\" \", os.path.basename(r), \"| weights:\", wp)\n",
        "\n",
        "def yolo_counts(root=YOLO_DATASET):\n",
        "    stats = {}\n",
        "    for s in [\"train\",\"valid\",\"test\"]:\n",
        "        ni = len([f for f in glob.glob(f\"{root}/{s}/images/*\") if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "        nl = len(glob.glob(f\"{root}/{s}/labels/*.txt\"))\n",
        "        stats[s] = (ni, nl)\n",
        "    return stats\n",
        "\n",
        "print(\"=== Existing runs ===\")\n",
        "list_runs()\n",
        "\n",
        "print(\"\\n=== Dataset counts (images, labels) ===\")\n",
        "counts = yolo_counts()\n",
        "for k,v in counts.items():\n",
        "    print(f\"  {k}: images={v[0]}  labels={v[1]}\")\n",
        "\n",
        "# If no labels -> show diagnostics\n",
        "if counts[\"train\"][1] == 0:\n",
        "    print(\"\\n‚ö†Ô∏è No training labels found. Diagnostics:\")\n",
        "    # show some ann filenames and a sample JSON content to inspect schema\n",
        "    sample_ann_dir = \"/content/drive/MyDrive/DENTALDATASET/train/ann\"\n",
        "    if os.path.isdir(sample_ann_dir):\n",
        "        files = sorted(glob.glob(os.path.join(sample_ann_dir, \"*\")) )[:10]\n",
        "        print(\" Sample ann files:\", files)\n",
        "        if files:\n",
        "            sample = files[0]\n",
        "            print(\"\\n--- Sample annotation file content (first 400 chars) ---\")\n",
        "            try:\n",
        "                with open(sample, \"r\") as f:\n",
        "                    txt = f.read(400)\n",
        "                print(txt)\n",
        "            except Exception as e:\n",
        "                print(\"Could not read sample file:\", e)\n",
        "    else:\n",
        "        print(\" Could not find annotation dir at:\", sample_ann_dir)\n",
        "\n",
        "    print(\"\\nIf labels are missing you have two main options:\")\n",
        "    print(\" A) Run the conversion scripts provided earlier (re-run robust converters).\")\n",
        "    print(\" B) If you have mask PNGs under train/masks, run the mask->labels converter.\")\n",
        "    print(\"\\nI can re-run conversion automatically (robust), or you can paste the output of the sample JSON above and I'll adapt conversion. Say 'auto convert' to let me re-run converters now, or 'train' to start training (will fail if labels still 0).\")\n",
        "else:\n",
        "    # quick sanity training to produce best.pt\n",
        "    print(\"\\n‚úÖ Found labels. Starting quick sanity training (5 epochs) to produce best.pt ...\")\n",
        "    model = YOLO(\"yolov8s-seg.pt\")\n",
        "    model.train(\n",
        "        data=\"/content/dental.yaml\",\n",
        "        epochs=5,\n",
        "        imgsz=640,\n",
        "        batch=8,\n",
        "        name=\"dental_quick_train_auto\",\n",
        "        verbose=True\n",
        "    )\n",
        "    print(\"\\n‚úÖ Quick training finished. Check /content/runs/segment for the new run and weights.\")\n"
      ],
      "metadata": {
        "id": "SOvylodeibeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# AUTO-CONVERT Supervisely-style ann/*.json ‚Üí YOLOv8-seg .txt labels (Tooth-only)\n",
        "# - Builds a classId -> className map by scanning JSONs and any meta files.\n",
        "# - Handles polygons stored in objects[].points.exterior or objects[].points\n",
        "# - Accepts filenames like '...jpg.json'\n",
        "# ==============================\n",
        "import os, glob, json, re, cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_DATASET = \"/content/drive/MyDrive/DENTALDATASET\"\n",
        "YOLO_DATASET   = \"/content/dentalai-yolo\"\n",
        "SPLITS = [\"train\",\"valid\",\"test\"]\n",
        "KEEP_WORD = \"tooth\"  # keep classes that contain this substring (case-insensitive)\n",
        "KEEP_RE = re.compile(re.escape(KEEP_WORD), re.IGNORECASE)\n",
        "\n",
        "def find_all_jsons(split):\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, split, \"ann\")\n",
        "    if not os.path.isdir(ann_dir):\n",
        "        return []\n",
        "    return sorted(glob.glob(os.path.join(ann_dir, \"*.json\")))\n",
        "\n",
        "# 1) Build classId -> name map by scanning all JSONs (look for classTitle / class_name / label / obj['classTitle'])\n",
        "id2name = {}\n",
        "examples = {}\n",
        "for split in SPLITS:\n",
        "    for jf in find_all_jsons(split):\n",
        "        try:\n",
        "            data = json.load(open(jf, \"r\"))\n",
        "        except Exception:\n",
        "            continue\n",
        "        # top-level categories/classes\n",
        "        if isinstance(data.get(\"classes\"), list):\n",
        "            # sometimes classes is list of dicts with id/name\n",
        "            for c in data.get(\"classes\", []):\n",
        "                cid = c.get(\"id\") or c.get(\"classId\") or c.get(\"class_id\") or None\n",
        "                name = c.get(\"title\") or c.get(\"name\") or c.get(\"title_ru\") or c.get(\"title_en\") or c.get(\"classTitle\") or c.get(\"title_latin\") or None\n",
        "                if cid is not None and name:\n",
        "                    id2name[int(cid)] = str(name)\n",
        "        if isinstance(data.get(\"categories\"), list):\n",
        "            for c in data.get(\"categories\", []):\n",
        "                cid = c.get(\"id\")\n",
        "                name = c.get(\"name\") or c.get(\"title\")\n",
        "                if cid is not None and name:\n",
        "                    id2name[int(cid)] = str(name)\n",
        "\n",
        "        # scan objects for classTitle/class_name\n",
        "        objs = data.get(\"objects\") or data.get(\"annotations\") or data.get(\"shapes\") or []\n",
        "        if isinstance(objs, list):\n",
        "            for o in objs:\n",
        "                if not isinstance(o, dict):\n",
        "                    continue\n",
        "                # prefer classTitle, then class_name, then label\n",
        "                name = o.get(\"classTitle\") or o.get(\"class_title\") or o.get(\"class_name\") or o.get(\"label\") or o.get(\"title\")\n",
        "                cid = o.get(\"classId\") or o.get(\"class_id\") or o.get(\"category_id\") or o.get(\"cat_id\")\n",
        "                if cid is None and isinstance(name, (int, float)):\n",
        "                    cid = int(name); name = None\n",
        "                if cid is not None and name:\n",
        "                    try:\n",
        "                        id2name[int(cid)] = str(name)\n",
        "                        examples[int(cid)] = os.path.basename(jf)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "# Print discovered mapping summary\n",
        "print(\"Discovered classId -> name (sample):\")\n",
        "for k in sorted(list(id2name.keys())[:20]):\n",
        "    print(\" \", k, \":\", id2name[k], \" example-json:\", examples.get(k, \"\"))\n",
        "\n",
        "# If no mapping found, try to infer from label strings in objects (rare)\n",
        "if not id2name:\n",
        "    print(\"No explicit classId->name mapping found in JSONs. Will try to infer names directly from object fields.\")\n",
        "\n",
        "# 2) For each split: find matching annotation file for each image and convert polygons where className contains 'tooth'\n",
        "def clamp01(x): return max(0.0, min(1.0, x))\n",
        "\n",
        "def normalize_poly(pts, w, h):\n",
        "    out = []\n",
        "    for p in pts:\n",
        "        x = float(p[0]); y = float(p[1])\n",
        "        out.append(clamp01(x / w))\n",
        "        out.append(clamp01(y / h))\n",
        "    return out\n",
        "\n",
        "def find_ann_for_image(ann_dir, basename):\n",
        "    # tries basename + \".json\", basename + \".*.json\" etc.\n",
        "    candidates = [\n",
        "        os.path.join(ann_dir, basename + \".json\"),\n",
        "        # handle names like base + \"_jpg.jpg.json\" or base + \".jpg.json\"\n",
        "        # search any file that starts with basename and ends with .json\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if os.path.exists(c):\n",
        "            return c\n",
        "    # fallback scan\n",
        "    for jf in glob.glob(os.path.join(ann_dir, basename + \"*\")):\n",
        "        if jf.lower().endswith(\".json\"):\n",
        "            return jf\n",
        "    return None\n",
        "\n",
        "written = {s:0 for s in SPLITS}\n",
        "for split in SPLITS:\n",
        "    img_dir = os.path.join(YOLO_DATASET, split, \"images\")\n",
        "    lab_dir = os.path.join(YOLO_DATASET, split, \"labels\"); os.makedirs(lab_dir, exist_ok=True)\n",
        "    ann_dir = os.path.join(SOURCE_DATASET, split, \"ann\")\n",
        "    if not os.path.isdir(img_dir):\n",
        "        print(\"Missing images dir:\", img_dir); continue\n",
        "    imgs = sorted([f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))])\n",
        "    for imgname in tqdm(imgs, desc=f\"Convert {split}\"):\n",
        "        base, ext = os.path.splitext(imgname)\n",
        "        img_path = os.path.join(img_dir, imgname)\n",
        "        out_txt = os.path.join(lab_dir, base + \".txt\")\n",
        "        # read size from actual image\n",
        "        im = cv2.imread(img_path)\n",
        "        if im is None:\n",
        "            continue\n",
        "        h, w = im.shape[:2]\n",
        "\n",
        "        jf = find_ann_for_image(ann_dir, base)\n",
        "        if jf is None:\n",
        "            # no annotation found, remove any stale label\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            data = json.load(open(jf, \"r\"))\n",
        "        except Exception:\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "            continue\n",
        "\n",
        "        polys_norm = []\n",
        "        objs = data.get(\"objects\") or data.get(\"annotations\") or data.get(\"shapes\") or []\n",
        "        for o in objs:\n",
        "            if not isinstance(o, dict):\n",
        "                continue\n",
        "            # get class name: try mapping first\n",
        "            cid = o.get(\"classId\") or o.get(\"class_id\") or o.get(\"category_id\") or o.get(\"cat_id\")\n",
        "            cname = None\n",
        "            if cid is not None and int(cid) in id2name:\n",
        "                cname = id2name[int(cid)]\n",
        "            # fallback to classTitle/class_name/label in object\n",
        "            if cname is None:\n",
        "                cname = o.get(\"classTitle\") or o.get(\"class_title\") or o.get(\"class_name\") or o.get(\"label\") or o.get(\"title\")\n",
        "\n",
        "            if not cname:\n",
        "                continue\n",
        "            if not KEEP_RE.search(str(cname)):\n",
        "                continue\n",
        "\n",
        "            # polygon points: Supervisely often stores o['points']['exterior'] = [[x,y],...]\n",
        "            pts = None\n",
        "            pts_field = o.get(\"points\") or o.get(\"geometry\") or o.get(\"vertices\") or None\n",
        "            if isinstance(pts_field, dict):\n",
        "                ext = pts_field.get(\"exterior\") or pts_field.get(\"points\") or pts_field.get(\"all_points\")\n",
        "                if isinstance(ext, list) and len(ext) >= 3:\n",
        "                    pts = []\n",
        "                    # items may be dict {'x':..,'y':..} or lists\n",
        "                    for p in ext:\n",
        "                        if isinstance(p, dict) and \"x\" in p and \"y\" in p:\n",
        "                            pts.append([float(p[\"x\"]), float(p[\"y\"])])\n",
        "                        elif isinstance(p, (list,tuple)) and len(p) >= 2:\n",
        "                            pts.append([float(p[0]), float(p[1])])\n",
        "            elif isinstance(pts_field, list) and len(pts_field) >= 3:\n",
        "                # may already be list of points\n",
        "                pts = []\n",
        "                for p in pts_field:\n",
        "                    if isinstance(p, dict) and \"x\" in p and \"y\" in p:\n",
        "                        pts.append([float(p[\"x\"]), float(p[\"y\"])])\n",
        "                    elif isinstance(p, (list,tuple)) and len(p) >= 2:\n",
        "                        pts.append([float(p[0]), float(p[1])])\n",
        "\n",
        "            # some datasets use \"geometryType\":\"polygon\" and \"points\" as list at top-level 'objects' entries\n",
        "            if pts is None:\n",
        "                # try known keys in object\n",
        "                if \"points\" in o and isinstance(o[\"points\"], list):\n",
        "                    pts = []\n",
        "                    for p in o[\"points\"]:\n",
        "                        if isinstance(p, dict) and \"x\" in p and \"y\" in p:\n",
        "                            pts.append([float(p[\"x\"]), float(p[\"y\"])])\n",
        "                        elif isinstance(p, (list,tuple)) and len(p) >= 2:\n",
        "                            pts.append([float(p[0]), float(p[1])])\n",
        "            if pts is None or len(pts) < 3:\n",
        "                continue\n",
        "\n",
        "            norm = normalize_poly(pts, w, h)\n",
        "            if len(norm) >= 6:\n",
        "                polys_norm.append(norm)\n",
        "\n",
        "        if polys_norm:\n",
        "            # write merged as multiple lines (YOLOv8 supports multiple polygons per image)\n",
        "            with open(out_txt, \"w\") as f:\n",
        "                for poly in polys_norm:\n",
        "                    f.write(\"0 \" + \" \".join(f\"{v:.6f}\" for v in poly) + \"\\n\")\n",
        "            written[split] += 1\n",
        "        else:\n",
        "            if os.path.exists(out_txt): os.remove(out_txt)\n",
        "\n",
        "print(\"\\nConversion complete. Label files written per split:\", written)\n",
        "\n",
        "# Final counts\n",
        "def yolo_counts(root=\"/content/dentalai-yolo\"):\n",
        "    stats = {}\n",
        "    for s in SPLITS:\n",
        "        ni = len([f for f in glob.glob(f\"{root}/{s}/images/*\") if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "        nl = len(glob.glob(f\"{root}/{s}/labels/*.txt\"))\n",
        "        stats[s] = (ni, nl)\n",
        "    return stats\n",
        "\n",
        "print(\"Counts now:\", yolo_counts())\n"
      ],
      "metadata": {
        "id": "fD8DgAtmr_cy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}